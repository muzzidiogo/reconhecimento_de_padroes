{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício: Dataset BreastCancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "np.random.seed(321)\n",
    "\n",
    "class myPerceptron:\n",
    "    def __init__(self, X: np.ndarray, Y: np.ndarray, eta: float, tol: float, max_epochs: int, par=1) -> None:\n",
    "        \"\"\"\n",
    "        Perceptron class. Adjust model weight based on training data.\n",
    "\n",
    "        Parameters:\n",
    "        X (ndarray): input data\n",
    "        Y (ndarray): target labels\n",
    "        eta (float): learning rate\n",
    "        tol (float): error tolerance\n",
    "        max_epochs (int): maximum number of epochs\n",
    "        \"\"\"\n",
    "        if par == 1:\n",
    "            # Add bias term to the input data\n",
    "            w = np.random.randn(X.shape[1] + 1)\n",
    "            X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        else:\n",
    "            w = np.random.randn(X.shape[1])\n",
    "        \n",
    "        N = len(X)\n",
    "        self.error_epoch = [tol + 1]\n",
    "        self.n_epoch = [0]\n",
    "        \n",
    "        while self.n_epoch[-1] < max_epochs and self.error_epoch[-1] > tol:\n",
    "            xseq = np.random.permutation(N)\n",
    "            ei2 = 0\n",
    "\n",
    "            for i in range(N):\n",
    "                i_rand = xseq[i]\n",
    "                err = Y[i_rand] - np.sign(np.dot(w, X[i_rand, :]))\n",
    "                w += eta * err * X[i_rand, :]\n",
    "                ei2 += err ** 2\n",
    "            self.error_epoch.append(ei2)\n",
    "            self.n_epoch.append(self.n_epoch[-1] + 1)\n",
    "        \n",
    "        self.weights = w\n",
    "\n",
    "    def predict(self, sample: np.ndarray, par=1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict sample class.\n",
    "\n",
    "        Parameters:\n",
    "        sample (ndarray): input data\n",
    "        \"\"\"\n",
    "        if par == 1:\n",
    "            # Add bias term to the input data\n",
    "            sample = np.hstack(((1,), sample))\n",
    "        output = np.dot(sample, self.weights)\n",
    "        return 1 if output >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados: (569, 30)\n",
      "Forma do alvo: (569,)\n",
      "Nomes das características: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Nomes das classes: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_data = load_breast_cancer()\n",
    "\n",
    "X = breast_cancer_data.data\n",
    "y = breast_cancer_data.target\n",
    "\n",
    "print(\"Forma dos dados:\", X.shape)  # (569, 30) - 569 amostras com 30 características\n",
    "print(\"Forma do alvo:\", y.shape)    # (569,) - 569 rótulos de classe\n",
    "\n",
    "print(\"Nomes das características:\", breast_cancer_data.feature_names)\n",
    "print(\"Nomes das classes:\", breast_cancer_data.target_names)  # [0 = 'malignant', 1 = 'benign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação em conjuntos para Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:61.40%\n",
      "Fold 2:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:63.16%\n",
      "Fold 3:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:57.89%\n",
      "Fold 4:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:84.21%\n",
      "Fold 5:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:63.16%\n",
      "Fold 6:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:89.47%\n",
      "Fold 7:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:63.16%\n",
      "Fold 8:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:63.16%\n",
      "Fold 9:\n",
      "  Train samples: 512, Test samples: 57\n",
      "  Model Accuracy:87.72%\n",
      "Fold 10:\n",
      "  Train samples: 513, Test samples: 56\n",
      "  Model Accuracy:89.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_list = []\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    perceptron = myPerceptron(X_train, y_train, eta = 0.1, tol = 0.1, max_epochs = 1000)\n",
    "    \n",
    "    y_predicted = [perceptron.predict(xi) for xi in X_test]\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    acc_list.append(accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train samples: {len(train_index)}, Test samples: {len(test_index)}\")\n",
    "    print(f\"  Model Accuracy:{100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo da Acurácia Média e Desvio Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média: 72.26%\n",
      "Standard Deviation: 12.74%\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = sum(acc_list)/len(acc_list)\n",
    "variance = sum((x - mean_accuracy) ** 2 for x in acc_list) / len(acc_list)\n",
    "std_dev = np.sqrt(variance)\n",
    "print(f\"Acurácia Média: {100*mean_accuracy:.2f}%\\nStandard Deviation: {100*std_dev:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
